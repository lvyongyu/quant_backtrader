"""
ç®€åŒ–æ•°æ®ç®¡ç†æ¨¡å— - Simplified Data Manager

ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£ï¼Œæ”¯æŒå†å²æ•°æ®å’Œå®æ—¶æ•°æ®ï¼Œ
è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ•°æ®æºï¼Œå†…ç½®æ™ºèƒ½ç¼“å­˜ã€‚

æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š
- ç®€åŒ–ä¼˜äºå¤æ‚ï¼šä¸€ä¸ªæ¥å£è§£å†³æ‰€æœ‰æ•°æ®éœ€æ±‚
- é»˜è®¤é…ç½®ï¼šå¼€ç®±å³ç”¨ï¼Œæ— éœ€å¤æ‚é…ç½®
- è‡ªåŠ¨é€‰æ‹©ï¼šæ™ºèƒ½é€‰æ‹©æœ€ä½³æ•°æ®æº
"""

import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union
import logging
import os
import pickle
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataManager:
    """
    ç®€åŒ–çš„æ•°æ®ç®¡ç†å™¨
    
    ç‰¹ç‚¹ï¼š
    - ç»Ÿä¸€æ¥å£è·å–å†å²æ•°æ®å’Œå®æ—¶æ•°æ®
    - è‡ªåŠ¨ç¼“å­˜ï¼Œæé«˜æ€§èƒ½
    - æ™ºèƒ½é”™è¯¯å¤„ç†å’Œé‡è¯•
    - æ”¯æŒå¤šç§æ—¶é—´å‘¨æœŸ
    """
    
    def __init__(self, cache_dir: str = None):
        """
        åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º ./data/cache
        """
        self.cache_dir = Path(cache_dir or "./data/cache")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¼“å­˜é…ç½®
        self.cache_enabled = True
        self.cache_expiry_hours = 24  # ç¼“å­˜24å°æ—¶
        
        logger.info(f"æ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œç¼“å­˜ç›®å½•ï¼š{self.cache_dir}")
    
    def get_data(self, 
                 symbol: str, 
                 period: str = "1y",
                 interval: str = "1d") -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨å†å²æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 'AAPL', 'GOOGL'
            period: æ—¶é—´å‘¨æœŸï¼Œæ”¯æŒ '1d', '5d', '1mo', '3mo', '6mo', '1y', '2y', '5y', '10y', 'ytd', 'max'
            interval: æ•°æ®é—´éš”ï¼Œæ”¯æŒ '1m', '2m', '5m', '15m', '30m', '60m', '90m', '1h', '1d', '5d', '1wk', '1mo', '3mo'
        
        Returns:
            åŒ…å«OHLCVæ•°æ®çš„DataFrame
        """
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{symbol}_{period}_{interval}"
            cached_data = self._get_cache(cache_key)
            if cached_data is not None:
                logger.info(f"ä»ç¼“å­˜è·å–æ•°æ®ï¼š{symbol}")
                return cached_data
            
            # ä»æ•°æ®æºè·å–
            logger.info(f"æ­£åœ¨è·å–æ•°æ®ï¼š{symbol}, å‘¨æœŸï¼š{period}, é—´éš”ï¼š{interval}")
            
            ticker = yf.Ticker(symbol)
            data = ticker.history(period=period, interval=interval)
            
            if data.empty:
                raise ValueError(f"æœªè·å–åˆ°æ•°æ®ï¼š{symbol}")
            
            # æ•°æ®æ¸…æ´—
            data = self._clean_data(data)
            
            # ä¿å­˜ç¼“å­˜
            self._save_cache(cache_key, data)
            
            logger.info(f"æ•°æ®è·å–æˆåŠŸï¼š{symbol}, {len(data)}æ¡è®°å½•")
            return data
            
        except Exception as e:
            logger.error(f"æ•°æ®è·å–å¤±è´¥ï¼š{symbol} - {e}")
            raise
    
    def get_data_by_date(self, 
                        symbol: str, 
                        start_date: str = None, 
                        end_date: str = None) -> pd.DataFrame:
        """
        æ ¹æ®æ—¥æœŸèŒƒå›´è·å–è‚¡ç¥¨æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼š'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼š'YYYY-MM-DD'
            
        Returns:
            è‚¡ç¥¨æ•°æ®DataFrame
        """
        try:
            ticker = yf.Ticker(symbol)
            
            if start_date and end_date:
                # ä½¿ç”¨æŒ‡å®šçš„æ—¥æœŸèŒƒå›´
                data = ticker.history(start=start_date, end=end_date)
            elif start_date:
                # åªæœ‰å¼€å§‹æ—¥æœŸï¼Œè·å–åˆ°ä»Šå¤©
                data = ticker.history(start=start_date)
            else:
                # é»˜è®¤è·å–1å¹´æ•°æ®
                data = ticker.history(period="1y")
            
            if data.empty:
                raise ValueError(f"æœªè·å–åˆ°æ•°æ®ï¼š{symbol}")
            
            # æ•°æ®æ¸…æ´—
            data = self._clean_data(data)
            
            logger.info(f"æ—¥æœŸèŒƒå›´æ•°æ®è·å–æˆåŠŸï¼š{symbol}, {len(data)}æ¡è®°å½•")
            return data
            
        except Exception as e:
            logger.error(f"æ—¥æœŸèŒƒå›´æ•°æ®è·å–å¤±è´¥ï¼š{symbol} - {e}")
            raise
    
    def get_realtime(self, symbol: str) -> Dict:
        """
        è·å–å®æ—¶æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            
        Returns:
            åŒ…å«å®æ—¶ä»·æ ¼ä¿¡æ¯çš„å­—å…¸
        """
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info
            
            # è·å–æœ€æ–°ä»·æ ¼
            hist = ticker.history(period="1d", interval="1m")
            if not hist.empty:
                latest = hist.iloc[-1]
                
                realtime_data = {
                    'symbol': symbol,
                    'price': float(latest['Close']),
                    'open': float(latest['Open']),
                    'high': float(latest['High']),
                    'low': float(latest['Low']),
                    'volume': int(latest['Volume']),
                    'timestamp': latest.name.isoformat(),
                    'change': 0.0,
                    'change_percent': 0.0
                }
                
                # è®¡ç®—æ¶¨è·Œ
                if len(hist) > 1:
                    prev_close = float(hist.iloc[-2]['Close'])
                    realtime_data['change'] = realtime_data['price'] - prev_close
                    realtime_data['change_percent'] = (realtime_data['change'] / prev_close) * 100
                
                logger.info(f"å®æ—¶æ•°æ®è·å–æˆåŠŸï¼š{symbol}, ä»·æ ¼ï¼š{realtime_data['price']}")
                return realtime_data
            
            raise ValueError(f"æ— æ³•è·å–å®æ—¶æ•°æ®ï¼š{symbol}")
            
        except Exception as e:
            logger.error(f"å®æ—¶æ•°æ®è·å–å¤±è´¥ï¼š{symbol} - {e}")
            raise
    
    def get_info(self, symbol: str) -> Dict:
        """
        è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            
        Returns:
            åŒ…å«è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯çš„å­—å…¸
        """
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info
            
            # æå–å…³é”®ä¿¡æ¯
            basic_info = {
                'symbol': symbol,
                'name': info.get('longName', 'N/A'),
                'sector': info.get('sector', 'N/A'),
                'industry': info.get('industry', 'N/A'),
                'market_cap': info.get('marketCap', 0),
                'pe_ratio': info.get('trailingPE', 0),
                'dividend_yield': info.get('dividendYield', 0),
                'beta': info.get('beta', 0),
                'description': info.get('longBusinessSummary', 'N/A')[:200] + '...'
            }
            
            logger.info(f"åŸºæœ¬ä¿¡æ¯è·å–æˆåŠŸï¼š{symbol}")
            return basic_info
            
        except Exception as e:
            logger.error(f"åŸºæœ¬ä¿¡æ¯è·å–å¤±è´¥ï¼š{symbol} - {e}")
            raise
    
    def get_multiple(self, symbols: List[str], period: str = "1y") -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            period: æ—¶é—´å‘¨æœŸ
            
        Returns:
            è‚¡ç¥¨ä»£ç ä¸ºé”®ï¼ŒDataFrameä¸ºå€¼çš„å­—å…¸
        """
        results = {}
        
        for symbol in symbols:
            try:
                results[symbol] = self.get_data(symbol, period)
                logger.info(f"æ‰¹é‡è·å–æˆåŠŸï¼š{symbol}")
            except Exception as e:
                logger.warning(f"æ‰¹é‡è·å–å¤±è´¥ï¼š{symbol} - {e}")
                continue
        
        logger.info(f"æ‰¹é‡è·å–å®Œæˆï¼š{len(results)}/{len(symbols)}åªè‚¡ç¥¨")
        return results
    
    def _clean_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´—æ•°æ®"""
        # ç§»é™¤ç©ºå€¼
        data = data.dropna()
        
        # ç¡®ä¿åˆ—åæ ‡å‡†åŒ–
        data.columns = [col.title() for col in data.columns]
        
        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        for col in numeric_columns:
            if col in data.columns:
                data[col] = pd.to_numeric(data[col], errors='coerce')
        
        return data
    
    def _get_cache(self, cache_key: str) -> Optional[pd.DataFrame]:
        """è·å–ç¼“å­˜æ•°æ®"""
        if not self.cache_enabled:
            return None
            
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        
        if cache_file.exists():
            # æ£€æŸ¥ç¼“å­˜æ—¶é—´
            cache_time = datetime.fromtimestamp(cache_file.stat().st_mtime)
            if datetime.now() - cache_time < timedelta(hours=self.cache_expiry_hours):
                try:
                    with open(cache_file, 'rb') as f:
                        return pickle.load(f)
                except Exception:
                    # ç¼“å­˜æ–‡ä»¶æŸåï¼Œåˆ é™¤
                    cache_file.unlink()
        
        return None
    
    def _save_cache(self, cache_key: str, data: pd.DataFrame):
        """ä¿å­˜ç¼“å­˜æ•°æ®"""
        if not self.cache_enabled:
            return
            
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(data, f)
        except Exception as e:
            logger.warning(f"ç¼“å­˜ä¿å­˜å¤±è´¥ï¼š{e}")
    
    def clear_cache(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        cache_files = list(self.cache_dir.glob("*.pkl"))
        for cache_file in cache_files:
            cache_file.unlink()
        
        logger.info(f"ç¼“å­˜æ¸…é™¤å®Œæˆï¼š{len(cache_files)}ä¸ªæ–‡ä»¶")
    
    def get_cache_info(self) -> Dict:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        cache_files = list(self.cache_dir.glob("*.pkl"))
        
        total_size = sum(f.stat().st_size for f in cache_files)
        
        return {
            'cache_enabled': self.cache_enabled,
            'cache_dir': str(self.cache_dir),
            'file_count': len(cache_files),
            'total_size_mb': round(total_size / 1024 / 1024, 2),
            'expiry_hours': self.cache_expiry_hours
        }


# ä¾¿æ·å‡½æ•°
def get_stock_data(symbol: str, period: str = "1y") -> pd.DataFrame:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        period: æ—¶é—´å‘¨æœŸ
        
    Returns:
        è‚¡ç¥¨æ•°æ®DataFrame
    """
    manager = DataManager()
    return manager.get_data(symbol, period)


def get_realtime_price(symbol: str) -> float:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–å®æ—¶ä»·æ ¼
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        
    Returns:
        å½“å‰ä»·æ ¼
    """
    manager = DataManager()
    data = manager.get_realtime(symbol)
    return data['price']


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
if __name__ == "__main__":
    print("ğŸš€ ç®€åŒ–æ•°æ®ç®¡ç†æ¨¡å—æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
    dm = DataManager()
    
    # æµ‹è¯•1ï¼šè·å–å†å²æ•°æ®
    print("\nğŸ“Š æµ‹è¯•å†å²æ•°æ®è·å–...")
    try:
        aapl_data = dm.get_data("AAPL", "1mo")
        print(f"âœ… AAPLæ•°æ®è·å–æˆåŠŸï¼š{len(aapl_data)}æ¡è®°å½•")
        print(f"   æ•°æ®èŒƒå›´ï¼š{aapl_data.index[0].date()} - {aapl_data.index[-1].date()}")
        print(f"   æœ€æ–°æ”¶ç›˜ä»·ï¼š${aapl_data['Close'].iloc[-1]:.2f}")
    except Exception as e:
        print(f"âŒ å†å²æ•°æ®è·å–å¤±è´¥ï¼š{e}")
    
    # æµ‹è¯•2ï¼šè·å–å®æ—¶æ•°æ®
    print("\nâš¡ æµ‹è¯•å®æ—¶æ•°æ®è·å–...")
    try:
        realtime = dm.get_realtime("AAPL")
        print(f"âœ… å®æ—¶æ•°æ®è·å–æˆåŠŸ")
        print(f"   å½“å‰ä»·æ ¼ï¼š${realtime['price']:.2f}")
        print(f"   æ¶¨è·Œå¹…ï¼š{realtime['change_percent']:+.2f}%")
    except Exception as e:
        print(f"âŒ å®æ—¶æ•°æ®è·å–å¤±è´¥ï¼š{e}")
    
    # æµ‹è¯•3ï¼šè·å–åŸºæœ¬ä¿¡æ¯
    print("\nğŸ“‹ æµ‹è¯•åŸºæœ¬ä¿¡æ¯è·å–...")
    try:
        info = dm.get_info("AAPL")
        print(f"âœ… åŸºæœ¬ä¿¡æ¯è·å–æˆåŠŸ")
        print(f"   å…¬å¸åç§°ï¼š{info['name']}")
        print(f"   è¡Œä¸šï¼š{info['sector']} - {info['industry']}")
        print(f"   å¸‚å€¼ï¼š${info['market_cap']:,}")
    except Exception as e:
        print(f"âŒ åŸºæœ¬ä¿¡æ¯è·å–å¤±è´¥ï¼š{e}")
    
    # æµ‹è¯•4ï¼šæ‰¹é‡è·å–
    print("\nğŸ“ˆ æµ‹è¯•æ‰¹é‡æ•°æ®è·å–...")
    try:
        symbols = ["AAPL", "GOOGL", "MSFT"]
        multiple_data = dm.get_multiple(symbols, "1mo")
        print(f"âœ… æ‰¹é‡è·å–æˆåŠŸï¼š{len(multiple_data)}åªè‚¡ç¥¨")
        for symbol, data in multiple_data.items():
            print(f"   {symbol}ï¼š{len(data)}æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ æ‰¹é‡è·å–å¤±è´¥ï¼š{e}")
    
    # æµ‹è¯•5ï¼šç¼“å­˜ä¿¡æ¯
    print("\nğŸ’¾ ç¼“å­˜ä¿¡æ¯...")
    cache_info = dm.get_cache_info()
    print(f"   ç¼“å­˜çŠ¶æ€ï¼š{'å¯ç”¨' if cache_info['cache_enabled'] else 'ç¦ç”¨'}")
    print(f"   ç¼“å­˜æ–‡ä»¶ï¼š{cache_info['file_count']}ä¸ª")
    print(f"   ç¼“å­˜å¤§å°ï¼š{cache_info['total_size_mb']}MB")
    
    # æµ‹è¯•6ï¼šä¾¿æ·å‡½æ•°
    print("\nğŸ”§ æµ‹è¯•ä¾¿æ·å‡½æ•°...")
    try:
        price = get_realtime_price("AAPL")
        print(f"âœ… ä¾¿æ·å‡½æ•°æµ‹è¯•æˆåŠŸï¼šAAPLå½“å‰ä»·æ ¼ ${price:.2f}")
    except Exception as e:
        print(f"âŒ ä¾¿æ·å‡½æ•°æµ‹è¯•å¤±è´¥ï¼š{e}")
    
    print("\n" + "=" * 50)
    print("ğŸ¯ ç®€åŒ–æ•°æ®ç®¡ç†æ¨¡å—æ ¸å¿ƒç‰¹æ€§ï¼š")
    print("  âœ… ç»Ÿä¸€æ¥å£ - ä¸€ä¸ªç±»è§£å†³æ‰€æœ‰æ•°æ®éœ€æ±‚")
    print("  âœ… æ™ºèƒ½ç¼“å­˜ - è‡ªåŠ¨ç¼“å­˜ï¼Œæé«˜æ€§èƒ½") 
    print("  âœ… é”™è¯¯å¤„ç† - å‹å¥½çš„é”™è¯¯æç¤º")
    print("  âœ… ä¾¿æ·å‡½æ•° - ç®€åŒ–å¸¸ç”¨æ“ä½œ")
    print("  âœ… æ‰¹é‡å¤„ç† - æ”¯æŒå¤šè‚¡ç¥¨æ•°æ®è·å–")
    print("=" * 50)

# ==================== ä¾¿æ·å‡½æ•° ====================

# åˆ›å»ºå…¨å±€æ•°æ®ç®¡ç†å™¨å®ä¾‹
_global_data_manager = DataManager()

def get_data(symbol: str, start_date: str = None, end_date: str = None, period: str = '1d') -> pd.DataFrame:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼š'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼š'YYYY-MM-DD'
        period: æ—¶é—´å‘¨æœŸ (å½“start_dateå’Œend_dateä¸ºNoneæ—¶ä½¿ç”¨)
        
    Returns:
        è‚¡ç¥¨æ•°æ®DataFrame
    """
    if start_date or end_date:
        return _global_data_manager.get_data_by_date(symbol, start_date, end_date)
    else:
        # è½¬æ¢periodåˆ°yfinanceæ ¼å¼
        if period == '1d':
            yf_period = '1y'
        elif period in ['1mo', '3mo', '6mo', '1y', '2y', '5y']:
            yf_period = period
        else:
            yf_period = '1y'
        return _global_data_manager.get_data(symbol, period=yf_period)

def get_realtime_price(symbol: str) -> float:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–å®æ—¶ä»·æ ¼
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        
    Returns:
        å½“å‰ä»·æ ¼
    """
    try:
        realtime_data = _global_data_manager.get_realtime(symbol)
        return realtime_data.get('price', 0.0)
    except:
        # å¦‚æœå®æ—¶æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨æœ€æ–°å†å²æ•°æ®
        try:
            data = _global_data_manager.get_data(symbol, period='1d')
            return float(data['Close'].iloc[-1]) if not data.empty else 0.0
        except:
            return 0.0

def get_stock_info(symbol: str) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–è‚¡ç¥¨ä¿¡æ¯
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        
    Returns:
        è‚¡ç¥¨ä¿¡æ¯å­—å…¸
    """
    return _global_data_manager.get_info(symbol)

def get_multiple_data(symbols: List[str], period: str = '1mo') -> Dict[str, pd.DataFrame]:
    """
    ä¾¿æ·å‡½æ•°ï¼šæ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        period: æ—¶é—´å‘¨æœŸ
        
    Returns:
        è‚¡ç¥¨æ•°æ®å­—å…¸
    """
    return _global_data_manager.get_multiple(symbols, period)