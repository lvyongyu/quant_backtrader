"""
ç­–ç•¥å›æµ‹æ•°æ®ç®¡ç†å™¨

è´Ÿè´£å†å²æ•°æ®è·å–ã€æ¸…æ´—ã€å­˜å‚¨å’Œç®¡ç†ï¼Œ
æ”¯æŒå¤šç§æ•°æ®æºå’Œæ•°æ®æ ¼å¼ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å†å²æ•°æ®è·å–
2. æ•°æ®æ¸…æ´—å’ŒéªŒè¯
3. æ•°æ®ç¼“å­˜ç®¡ç†
4. æ•°æ®æ ¼å¼æ ‡å‡†åŒ–
5. åŸºå‡†æ•°æ®ç®¡ç†
"""

import os
import json
import pickle
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
import logging

# åŸºç¡€æ•°æ®ç»“æ„
class MarketData:
    """å¸‚åœºæ•°æ®åŸºç¡€ç±»"""
    def __init__(self, symbol: str, date: datetime, 
                 open_price: float, high: float, low: float, 
                 close: float, volume: int = 0):
        self.symbol = symbol
        self.date = date
        self.open = open_price
        self.high = high
        self.low = low
        self.close = close
        self.volume = volume
        self.adjusted_close = close  # å¤æƒä»·æ ¼
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'symbol': self.symbol,
            'date': self.date.isoformat(),
            'open': self.open,
            'high': self.high,
            'low': self.low,
            'close': self.close,
            'volume': self.volume,
            'adjusted_close': self.adjusted_close
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'MarketData':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(
            symbol=data['symbol'],
            date=datetime.fromisoformat(data['date']) if isinstance(data['date'], str) else data['date'],
            open_price=data['open'],
            high=data['high'],
            low=data['low'],
            close=data['close'],
            volume=data.get('volume', 0)
        )
    
    def validate(self) -> bool:
        """æ•°æ®éªŒè¯"""
        if self.high < max(self.open, self.close):
            return False
        if self.low > min(self.open, self.close):
            return False
        if any(price < 0 for price in [self.open, self.high, self.low, self.close]):
            return False
        if self.volume < 0:
            return False
        return True


class DataProvider:
    """æ•°æ®æä¾›è€…åŸºç¡€æ¥å£"""
    
    def __init__(self, name: str):
        self.name = name
        self.logger = logging.getLogger(f"DataProvider.{name}")
    
    def get_historical_data(self, symbol: str, start_date: str, end_date: str, 
                           interval: str = "1d") -> List[MarketData]:
        """è·å–å†å²æ•°æ®"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")
    
    def get_symbols_list(self, market: str = "US") -> List[str]:
        """è·å–å¯ç”¨è‚¡ç¥¨åˆ—è¡¨"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")


class CSVDataProvider(DataProvider):
    """CSVæ–‡ä»¶æ•°æ®æä¾›è€…"""
    
    def __init__(self, data_dir: str):
        super().__init__("CSV")
        self.data_dir = data_dir
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(data_dir, exist_ok=True)
    
    def get_historical_data(self, symbol: str, start_date: str, end_date: str, 
                           interval: str = "1d") -> List[MarketData]:
        """ä»CSVæ–‡ä»¶è¯»å–å†å²æ•°æ®"""
        file_path = os.path.join(self.data_dir, f"{symbol}.csv")
        
        if not os.path.exists(file_path):
            self.logger.warning(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return []
        
        data_list = []
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
                # è·³è¿‡è¡¨å¤´
                if lines and lines[0].startswith('date'):
                    lines = lines[1:]
                
                for line in lines:
                    parts = line.strip().split(',')
                    if len(parts) >= 6:
                        try:
                            date = datetime.strptime(parts[0], "%Y-%m-%d")
                            
                            # æ—¥æœŸè¿‡æ»¤
                            if start_dt <= date <= end_dt:
                                market_data = MarketData(
                                    symbol=symbol,
                                    date=date,
                                    open_price=float(parts[1]),
                                    high=float(parts[2]),
                                    low=float(parts[3]),
                                    close=float(parts[4]),
                                    volume=int(float(parts[5])) if parts[5] else 0
                                )
                                
                                if market_data.validate():
                                    data_list.append(market_data)
                        
                        except (ValueError, IndexError) as e:
                            self.logger.warning(f"æ•°æ®è§£æé”™è¯¯: {line.strip()}, {e}")
                            continue
        
        except Exception as e:
            self.logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
            return []
        
        return sorted(data_list, key=lambda x: x.date)
    
    def save_data(self, symbol: str, data: List[MarketData]):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        file_path = os.path.join(self.data_dir, f"{symbol}.csv")
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                # å†™å…¥è¡¨å¤´
                f.write("date,open,high,low,close,volume\\n")
                
                # å†™å…¥æ•°æ®
                for market_data in sorted(data, key=lambda x: x.date):
                    f.write(f"{market_data.date.strftime('%Y-%m-%d')},"
                           f"{market_data.open},{market_data.high},"
                           f"{market_data.low},{market_data.close},"
                           f"{market_data.volume}\\n")
            
            self.logger.info(f"æ•°æ®ä¿å­˜æˆåŠŸ: {symbol}, {len(data)}æ¡è®°å½•")
        
        except Exception as e:
            self.logger.error(f"ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")


class MockDataProvider(DataProvider):
    """æ¨¡æ‹Ÿæ•°æ®æä¾›è€…ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    
    def __init__(self):
        super().__init__("Mock")
        # ä½¿ç”¨ç®€å•çš„éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆé¿å…numpyä¾èµ–ï¼‰
        import random
        self.random = random
        self.random.seed(42)  # å›ºå®šç§å­ç¡®ä¿å¯é‡å¤
    
    def get_historical_data(self, symbol: str, start_date: str, end_date: str, 
                           interval: str = "1d") -> List[MarketData]:
        """ç”Ÿæˆæ¨¡æ‹Ÿå†å²æ•°æ®"""
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        
        data_list = []
        current_date = start_dt
        current_price = 100.0  # åˆå§‹ä»·æ ¼
        
        while current_date <= end_dt:
            # éšæœºä»·æ ¼å˜åŠ¨
            change_pct = (self.random.random() - 0.5) * 0.04  # -2% to +2%
            new_price = current_price * (1 + change_pct)
            
            # ç”ŸæˆOHLCæ•°æ®
            high_offset = self.random.random() * 0.02  # 0-2%
            low_offset = self.random.random() * 0.02   # 0-2%
            
            open_price = current_price
            close_price = new_price
            high_price = max(open_price, close_price) * (1 + high_offset)
            low_price = min(open_price, close_price) * (1 - low_offset)
            
            # ç”Ÿæˆæˆäº¤é‡
            volume = int(self.random.uniform(100000, 1000000))
            
            market_data = MarketData(
                symbol=symbol,
                date=current_date,
                open_price=open_price,
                high=high_price,
                low=low_price,
                close=close_price,
                volume=volume
            )
            
            data_list.append(market_data)
            current_price = new_price
            current_date += timedelta(days=1)
            
            # è·³è¿‡å‘¨æœ«
            if current_date.weekday() >= 5:
                current_date += timedelta(days=2)
        
        return data_list
    
    def get_symbols_list(self, market: str = "US") -> List[str]:
        """è·å–æ¨¡æ‹Ÿè‚¡ç¥¨åˆ—è¡¨"""
        return ["AAPL", "GOOGL", "MSFT", "TSLA", "AMZN", "NVDA", "META"]


class DataCache:
    """æ•°æ®ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = "data/cache"):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
        self.logger = logging.getLogger("DataCache")
    
    def get_cache_key(self, symbol: str, start_date: str, end_date: str, interval: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{symbol}_{start_date}_{end_date}_{interval}"
    
    def get_cache_file(self, cache_key: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.cache_dir, f"{cache_key}.pkl")
    
    def is_cached(self, symbol: str, start_date: str, end_date: str, interval: str) -> bool:
        """æ£€æŸ¥æ•°æ®æ˜¯å¦å·²ç¼“å­˜"""
        cache_key = self.get_cache_key(symbol, start_date, end_date, interval)
        cache_file = self.get_cache_file(cache_key)
        return os.path.exists(cache_file)
    
    def get_cached_data(self, symbol: str, start_date: str, end_date: str, 
                       interval: str) -> Optional[List[MarketData]]:
        """è·å–ç¼“å­˜æ•°æ®"""
        if not self.is_cached(symbol, start_date, end_date, interval):
            return None
        
        cache_key = self.get_cache_key(symbol, start_date, end_date, interval)
        cache_file = self.get_cache_file(cache_key)
        
        try:
            with open(cache_file, 'rb') as f:
                cached_data = pickle.load(f)
                
                # éªŒè¯ç¼“å­˜æ•°æ®
                if isinstance(cached_data, dict) and 'data' in cached_data:
                    cache_time = cached_data.get('timestamp', 0)
                    
                    # ç¼“å­˜æœ‰æ•ˆæœŸæ£€æŸ¥ï¼ˆ24å°æ—¶ï¼‰
                    if datetime.now().timestamp() - cache_time < 86400:
                        self.logger.debug(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
                        return cached_data['data']
                    else:
                        self.logger.debug(f"ç¼“å­˜è¿‡æœŸ: {cache_key}")
                        return None
        
        except Exception as e:
            self.logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {cache_key}, {e}")
            return None
        
        return None
    
    def cache_data(self, symbol: str, start_date: str, end_date: str, 
                   interval: str, data: List[MarketData]):
        """ç¼“å­˜æ•°æ®"""
        cache_key = self.get_cache_key(symbol, start_date, end_date, interval)
        cache_file = self.get_cache_file(cache_key)
        
        try:
            cache_data = {
                'timestamp': datetime.now().timestamp(),
                'symbol': symbol,
                'start_date': start_date,
                'end_date': end_date,
                'interval': interval,
                'data': data
            }
            
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            
            self.logger.debug(f"æ•°æ®å·²ç¼“å­˜: {cache_key}, {len(data)}æ¡è®°å½•")
        
        except Exception as e:
            self.logger.warning(f"ç¼“å­˜æ•°æ®å¤±è´¥: {cache_key}, {e}")
    
    def clear_cache(self, symbol: str = None):
        """æ¸…ç†ç¼“å­˜"""
        try:
            if symbol:
                # æ¸…ç†ç‰¹å®šè‚¡ç¥¨çš„ç¼“å­˜
                for file_name in os.listdir(self.cache_dir):
                    if file_name.startswith(f"{symbol}_"):
                        file_path = os.path.join(self.cache_dir, file_name)
                        os.remove(file_path)
                        self.logger.info(f"æ¸…ç†ç¼“å­˜: {file_name}")
            else:
                # æ¸…ç†æ‰€æœ‰ç¼“å­˜
                for file_name in os.listdir(self.cache_dir):
                    if file_name.endswith('.pkl'):
                        file_path = os.path.join(self.cache_dir, file_name)
                        os.remove(file_path)
                        self.logger.info(f"æ¸…ç†ç¼“å­˜: {file_name}")
        
        except Exception as e:
            self.logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")


class HistoricalDataManager:
    """
    å†å²æ•°æ®ç®¡ç†å™¨
    
    ç»Ÿä¸€ç®¡ç†å¤šç§æ•°æ®æºï¼Œæä¾›ç¼“å­˜æœºåˆ¶ï¼Œ
    ç¡®ä¿æ•°æ®è´¨é‡å’Œè®¿é—®æ•ˆç‡ã€‚
    """
    
    def __init__(self, cache_dir: str = "data/cache"):
        self.providers = {}
        self.cache = DataCache(cache_dir)
        self.logger = logging.getLogger("HistoricalDataManager")
        
        # æ³¨å†Œé»˜è®¤æ•°æ®æä¾›è€…
        self.register_provider("mock", MockDataProvider())
        self.register_provider("csv", CSVDataProvider("data/historical"))
    
    def register_provider(self, name: str, provider: DataProvider):
        """æ³¨å†Œæ•°æ®æä¾›è€…"""
        self.providers[name] = provider
        self.logger.info(f"æ³¨å†Œæ•°æ®æä¾›è€…: {name}")
    
    def get_data(self, symbol: str, start_date: str, end_date: str, 
                 interval: str = "1d", provider: str = "mock", 
                 use_cache: bool = True) -> List[MarketData]:
        """
        è·å–å†å²æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            interval: æ•°æ®é—´éš”
            provider: æ•°æ®æä¾›è€…åç§°
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        
        Returns:
            å†å²æ•°æ®åˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cached_data = self.cache.get_cached_data(symbol, start_date, end_date, interval)
            if cached_data:
                return cached_data
        
        # è·å–æ•°æ®æä¾›è€…
        if provider not in self.providers:
            raise ValueError(f"æœªçŸ¥çš„æ•°æ®æä¾›è€…: {provider}")
        
        data_provider = self.providers[provider]
        
        try:
            # è·å–æ•°æ®
            data = data_provider.get_historical_data(symbol, start_date, end_date, interval)
            
            # æ•°æ®éªŒè¯å’Œæ¸…æ´—
            cleaned_data = self._clean_data(data)
            
            # ç¼“å­˜æ•°æ®
            if use_cache and cleaned_data:
                self.cache.cache_data(symbol, start_date, end_date, interval, cleaned_data)
            
            self.logger.info(f"è·å–æ•°æ®æˆåŠŸ: {symbol} {start_date}-{end_date}, {len(cleaned_data)}æ¡è®°å½•")
            
            return cleaned_data
        
        except Exception as e:
            self.logger.error(f"è·å–æ•°æ®å¤±è´¥: {symbol}, {e}")
            return []
    
    def _clean_data(self, data: List[MarketData]) -> List[MarketData]:
        """æ•°æ®æ¸…æ´—"""
        if not data:
            return []
        
        cleaned_data = []
        
        for market_data in data:
            # æ•°æ®éªŒè¯
            if not market_data.validate():
                self.logger.warning(f"æ— æ•ˆæ•°æ®: {market_data.symbol} {market_data.date}")
                continue
            
            # ä»·æ ¼åˆç†æ€§æ£€æŸ¥
            if market_data.close <= 0 or market_data.close > 10000:
                self.logger.warning(f"å¼‚å¸¸ä»·æ ¼: {market_data.symbol} {market_data.date} ${market_data.close}")
                continue
            
            cleaned_data.append(market_data)
        
        # æŒ‰æ—¥æœŸæ’åº
        cleaned_data.sort(key=lambda x: x.date)
        
        # æ£€æŸ¥æ•°æ®è¿ç»­æ€§
        if len(cleaned_data) > 1:
            gaps = self._check_data_gaps(cleaned_data)
            if gaps:
                self.logger.warning(f"æ•°æ®ç¼ºå£: {len(gaps)}ä¸ª")
        
        return cleaned_data
    
    def _check_data_gaps(self, data: List[MarketData]) -> List[Tuple[datetime, datetime]]:
        """æ£€æŸ¥æ•°æ®ç¼ºå£"""
        gaps = []
        
        for i in range(1, len(data)):
            prev_date = data[i-1].date
            curr_date = data[i].date
            
            # è®¡ç®—é¢„æœŸçš„ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
            expected_date = prev_date + timedelta(days=1)
            
            # è·³è¿‡å‘¨æœ«
            while expected_date.weekday() >= 5:
                expected_date += timedelta(days=1)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå£ï¼ˆè¶…è¿‡3å¤©ï¼‰
            if (curr_date - prev_date).days > 3:
                gaps.append((prev_date, curr_date))
        
        return gaps
    
    def get_symbols_list(self, provider: str = "mock", market: str = "US") -> List[str]:
        """è·å–å¯ç”¨è‚¡ç¥¨åˆ—è¡¨"""
        if provider not in self.providers:
            raise ValueError(f"æœªçŸ¥çš„æ•°æ®æä¾›è€…: {provider}")
        
        return self.providers[provider].get_symbols_list(market)
    
    def preload_data(self, symbols: List[str], start_date: str, end_date: str,
                     provider: str = "mock", interval: str = "1d"):
        """é¢„åŠ è½½æ•°æ®"""
        self.logger.info(f"å¼€å§‹é¢„åŠ è½½æ•°æ®: {len(symbols)}ä¸ªè‚¡ç¥¨")
        
        for symbol in symbols:
            try:
                self.get_data(symbol, start_date, end_date, interval, provider)
                self.logger.debug(f"é¢„åŠ è½½å®Œæˆ: {symbol}")
            except Exception as e:
                self.logger.error(f"é¢„åŠ è½½å¤±è´¥: {symbol}, {e}")
        
        self.logger.info("æ•°æ®é¢„åŠ è½½å®Œæˆ")
    
    def get_data_info(self, symbol: str, provider: str = "mock") -> Dict:
        """è·å–æ•°æ®ä¿¡æ¯"""
        try:
            # è·å–æœ€è¿‘ä¸€å¹´çš„æ•°æ®
            end_date = datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
            
            data = self.get_data(symbol, start_date, end_date, provider=provider)
            
            if not data:
                return {"symbol": symbol, "available": False}
            
            return {
                "symbol": symbol,
                "available": True,
                "records": len(data),
                "start_date": data[0].date.strftime("%Y-%m-%d"),
                "end_date": data[-1].date.strftime("%Y-%m-%d"),
                "price_range": {
                    "min": min(d.low for d in data),
                    "max": max(d.high for d in data),
                    "latest": data[-1].close
                },
                "volume_stats": {
                    "avg": sum(d.volume for d in data) / len(data),
                    "max": max(d.volume for d in data)
                }
            }
        
        except Exception as e:
            self.logger.error(f"è·å–æ•°æ®ä¿¡æ¯å¤±è´¥: {symbol}, {e}")
            return {"symbol": symbol, "available": False, "error": str(e)}


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
if __name__ == "__main__":
    print("ğŸ“ˆ ç­–ç•¥å›æµ‹æ•°æ®ç®¡ç†å™¨")
    print("=" * 50)
    
    # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
    data_manager = HistoricalDataManager()
    print("âœ… æ•°æ®ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯•æ¨¡æ‹Ÿæ•°æ®æä¾›è€…
    print("\\nğŸ”§ æµ‹è¯•æ¨¡æ‹Ÿæ•°æ®...")
    test_data = data_manager.get_data(
        symbol="AAPL",
        start_date="2023-01-01",
        end_date="2023-01-31",
        provider="mock"
    )
    
    print(f"âœ… è·å–æ•°æ®: {len(test_data)}æ¡è®°å½•")
    if test_data:
        print(f"  æ—¥æœŸèŒƒå›´: {test_data[0].date.strftime('%Y-%m-%d')} - {test_data[-1].date.strftime('%Y-%m-%d')}")
        print(f"  ä»·æ ¼èŒƒå›´: ${test_data[0].close:.2f} - ${test_data[-1].close:.2f}")
    
    # æµ‹è¯•æ•°æ®ç¼“å­˜
    print("\\nğŸ’¾ æµ‹è¯•æ•°æ®ç¼“å­˜...")
    cached_data = data_manager.get_data(
        symbol="AAPL",
        start_date="2023-01-01",
        end_date="2023-01-31",
        provider="mock",
        use_cache=True
    )
    print(f"âœ… ç¼“å­˜æµ‹è¯•: {len(cached_data)}æ¡è®°å½•")
    
    # æµ‹è¯•æ•°æ®ä¿¡æ¯
    print("\\nğŸ“Š æµ‹è¯•æ•°æ®ä¿¡æ¯...")
    info = data_manager.get_data_info("AAPL", "mock")
    print(f"âœ… æ•°æ®ä¿¡æ¯: {info}")
    
    # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
    print("\\nğŸ“‹ æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨...")
    symbols = data_manager.get_symbols_list("mock")
    print(f"âœ… å¯ç”¨è‚¡ç¥¨: {symbols}")
    
    print("\\nğŸ¯ æ•°æ®ç®¡ç†å™¨æ ¸å¿ƒåŠŸèƒ½:")
    print("  - å¤šæ•°æ®æºæ”¯æŒ âœ…")
    print("  - æ•°æ®ç¼“å­˜æœºåˆ¶ âœ…") 
    print("  - æ•°æ®æ¸…æ´—éªŒè¯ âœ…")
    print("  - æ•°æ®ç¼ºå£æ£€æµ‹ âœ…")
    print("  - æ‰¹é‡æ•°æ®é¢„åŠ è½½ âœ…")
    
    print("\\nğŸ”§ ä¸‹ä¸€æ­¥é›†æˆ:")
    print("  1. Yahoo Finance APIé›†æˆ")
    print("  2. å®æ—¶æ•°æ®æºé›†æˆ")
    print("  3. åŸºå‡†æ•°æ®ç®¡ç†")
    print("  4. æ•°æ®è´¨é‡ç›‘æ§")
    
    print("\\n" + "=" * 50)