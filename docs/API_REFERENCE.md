# P1-2 é«˜çº§é‡åŒ–äº¤æ˜“ç»„ä»¶ API å‚è€ƒæ–‡æ¡£

## ğŸ“‹ ç›®å½•

1. [é«˜çº§åˆ†æç»„ä»¶ API](#é«˜çº§åˆ†æç»„ä»¶-api)
2. [æœºå™¨å­¦ä¹ é›†æˆ API](#æœºå™¨å­¦ä¹ é›†æˆ-api)
3. [æŠ•èµ„ç»„åˆåˆ†æ API](#æŠ•èµ„ç»„åˆåˆ†æ-api)
4. [æ•°æ®ç»“æ„å‚è€ƒ](#æ•°æ®ç»“æ„å‚è€ƒ)
5. [é…ç½®é€‰é¡¹](#é…ç½®é€‰é¡¹)

---

## ğŸ”¬ é«˜çº§åˆ†æç»„ä»¶ API

### AdvancedIndicators ç±»

**åŠŸèƒ½**: æä¾›50+é«˜çº§æŠ€æœ¯æŒ‡æ ‡è®¡ç®—

#### åˆå§‹åŒ–
```python
from advanced_analytics.technical_indicators import AdvancedIndicators

indicators = AdvancedIndicators(
    use_cache=True,           # æ˜¯å¦å¯ç”¨è®¡ç®—ç¼“å­˜
    cache_size=1000,          # ç¼“å­˜å¤§å°
    validate_inputs=True      # æ˜¯å¦éªŒè¯è¾“å…¥æ•°æ®
)
```

#### æ ¸å¿ƒæ–¹æ³•

##### calculate_rsi()
```python
def calculate_rsi(
    self,
    prices: pd.Series,
    period: int = 14,
    overbought: float = 70,
    oversold: float = 30
) -> IndicatorResult
```

**å‚æ•°**:
- `prices` (pd.Series): ä»·æ ¼åºåˆ—
- `period` (int): RSIè®¡ç®—å‘¨æœŸï¼Œé»˜è®¤14
- `overbought` (float): è¶…ä¹°é˜ˆå€¼ï¼Œé»˜è®¤70
- `oversold` (float): è¶…å–é˜ˆå€¼ï¼Œé»˜è®¤30

**è¿”å›**: `IndicatorResult` å¯¹è±¡

**ç¤ºä¾‹**:
```python
rsi_result = indicators.calculate_rsi(
    prices=stock_prices,
    period=14,
    overbought=75,
    oversold=25
)

print(f"å½“å‰RSI: {rsi_result.values.iloc[-1]:.2f}")
print(f"ä¿¡å·è§£è¯»: {rsi_result.interpretation}")
```

##### calculate_macd()
```python
def calculate_macd(
    self,
    prices: pd.Series,
    fast_period: int = 12,
    slow_period: int = 26,
    signal_period: int = 9
) -> IndicatorResult
```

**å‚æ•°**:
- `prices` (pd.Series): ä»·æ ¼åºåˆ—
- `fast_period` (int): å¿«çº¿EMAå‘¨æœŸï¼Œé»˜è®¤12
- `slow_period` (int): æ…¢çº¿EMAå‘¨æœŸï¼Œé»˜è®¤26
- `signal_period` (int): ä¿¡å·çº¿EMAå‘¨æœŸï¼Œé»˜è®¤9

**è¿”å›**: `IndicatorResult` å¯¹è±¡ï¼ŒåŒ…å«MACDçº¿ã€ä¿¡å·çº¿å’ŒæŸ±çŠ¶å›¾

**ç¤ºä¾‹**:
```python
macd_result = indicators.calculate_macd(prices=stock_prices)

# è·å–MACDç»„ä»¶
macd_line = macd_result.values['macd']
signal_line = macd_result.values['signal']
histogram = macd_result.values['histogram']

# æ£€æŸ¥é‡‘å‰æ­»å‰
if macd_line.iloc[-1] > signal_line.iloc[-1] and macd_line.iloc[-2] <= signal_line.iloc[-2]:
    print("MACDé‡‘å‰ä¿¡å·ï¼")
```

##### calculate_bollinger_bands()
```python
def calculate_bollinger_bands(
    self,
    prices: pd.Series,
    period: int = 20,
    std_dev: float = 2.0,
    ma_type: str = 'sma'
) -> IndicatorResult
```

**å‚æ•°**:
- `prices` (pd.Series): ä»·æ ¼åºåˆ—
- `period` (int): ç§»åŠ¨å¹³å‡å‘¨æœŸï¼Œé»˜è®¤20
- `std_dev` (float): æ ‡å‡†å·®å€æ•°ï¼Œé»˜è®¤2.0
- `ma_type` (str): ç§»åŠ¨å¹³å‡ç±»å‹ï¼Œ'sma'æˆ–'ema'

**è¿”å›**: `IndicatorResult` å¯¹è±¡ï¼ŒåŒ…å«ä¸Šè½¨ã€ä¸­è½¨ã€ä¸‹è½¨

##### calculate_multiple_indicators()
```python
def calculate_multiple_indicators(
    self,
    price_data: pd.Series,
    indicator_list: List[str],
    **kwargs
) -> Dict[str, IndicatorResult]
```

**å‚æ•°**:
- `price_data` (pd.Series): ä»·æ ¼æ•°æ®
- `indicator_list` (List[str]): æŒ‡æ ‡åç§°åˆ—è¡¨
- `**kwargs`: å„æŒ‡æ ‡çš„å‚æ•°

**å¯ç”¨æŒ‡æ ‡**:
- `'rsi'`: ç›¸å¯¹å¼ºå¼±æŒ‡æ•°
- `'macd'`: MACDæŒ‡æ ‡
- `'bollinger_bands'`: å¸ƒæ—å¸¦
- `'stochastic'`: éšæœºæŒ‡æ ‡
- `'williams_r'`: å¨å»‰æŒ‡æ ‡
- `'cci'`: é¡ºåŠ¿æŒ‡æ ‡
- `'atr'`: å¹³å‡çœŸå®æ³¢å¹…
- `'adx'`: å¹³å‡è¶‹å‘æŒ‡æ ‡

**ç¤ºä¾‹**:
```python
multi_results = indicators.calculate_multiple_indicators(
    stock_prices,
    ['rsi', 'macd', 'bollinger_bands'],
    rsi_period=14,
    macd_fast_period=12,
    bollinger_period=20
)

for indicator_name, result in multi_results.items():
    print(f"{indicator_name}: {result.interpretation}")
```

### StatisticalAnalyzer ç±»

**åŠŸèƒ½**: ç»Ÿè®¡åˆ†æå’Œæ•°æ®æŒ–æ˜

#### åˆå§‹åŒ–
```python
from advanced_analytics.statistical_analysis import StatisticalAnalyzer

analyzer = StatisticalAnalyzer(
    confidence_level=0.95,    # ç½®ä¿¡æ°´å¹³
    random_state=42          # éšæœºç§å­
)
```

#### æ ¸å¿ƒæ–¹æ³•

##### calculate_correlation_analysis()
```python
def calculate_correlation_analysis(
    self,
    data1: pd.Series,
    data2: pd.Series,
    method: str = 'pearson',
    test_significance: bool = True
) -> AnalysisResult
```

**å‚æ•°**:
- `data1, data2` (pd.Series): å¾…åˆ†æçš„æ•°æ®åºåˆ—
- `method` (str): ç›¸å…³æ€§æ–¹æ³•ï¼Œ'pearson'ã€'spearman'ã€'kendall'
- `test_significance` (bool): æ˜¯å¦è¿›è¡Œæ˜¾è‘—æ€§æ£€éªŒ

**ç¤ºä¾‹**:
```python
correlation_result = analyzer.calculate_correlation_analysis(
    stock1_returns, stock2_returns, method='pearson'
)

print(f"ç›¸å…³ç³»æ•°: {correlation_result.results['correlation']:.3f}")
print(f"På€¼: {correlation_result.results['p_value']:.4f}")
print(f"æ˜¾è‘—æ€§: {'æ˜¾è‘—' if correlation_result.results['p_value'] < 0.05 else 'ä¸æ˜¾è‘—'}")
```

##### perform_regression_analysis()
```python
def perform_regression_analysis(
    self,
    dependent_var: pd.Series,
    independent_vars: pd.DataFrame,
    method: str = 'ols',
    include_diagnostics: bool = True
) -> AnalysisResult
```

**å‚æ•°**:
- `dependent_var` (pd.Series): å› å˜é‡
- `independent_vars` (pd.DataFrame): è‡ªå˜é‡
- `method` (str): å›å½’æ–¹æ³•ï¼Œ'ols'ã€'ridge'ã€'lasso'
- `include_diagnostics` (bool): æ˜¯å¦åŒ…å«è¯Šæ–­ä¿¡æ¯

##### analyze_distribution()
```python
def analyze_distribution(
    self,
    data: pd.Series,
    test_normality: bool = True,
    calculate_moments: bool = True,
    fit_distributions: List[str] = None
) -> AnalysisResult
```

**å‚æ•°**:
- `data` (pd.Series): å¾…åˆ†ææ•°æ®
- `test_normality` (bool): æ˜¯å¦è¿›è¡Œæ­£æ€æ€§æ£€éªŒ
- `calculate_moments` (bool): æ˜¯å¦è®¡ç®—çŸ©ç»Ÿè®¡é‡
- `fit_distributions` (List[str]): å¾…æ‹Ÿåˆçš„åˆ†å¸ƒç±»å‹

### AnomalyDetectionEngine ç±»

**åŠŸèƒ½**: å¤šç®—æ³•å¼‚å¸¸æ£€æµ‹

#### æ ¸å¿ƒæ–¹æ³•

##### detect_anomalies_isolation_forest()
```python
def detect_anomalies_isolation_forest(
    self,
    data: pd.DataFrame,
    contamination: float = 0.1,
    features: List[str] = None,
    random_state: int = 42
) -> AnomalyResult
```

**å‚æ•°**:
- `data` (pd.DataFrame): è¾“å…¥æ•°æ®
- `contamination` (float): å¼‚å¸¸å€¼æ¯”ä¾‹ä¼°è®¡
- `features` (List[str]): ç”¨äºæ£€æµ‹çš„ç‰¹å¾åˆ—
- `random_state` (int): éšæœºç§å­

##### detect_statistical_anomalies()
```python
def detect_statistical_anomalies(
    self,
    data: pd.Series,
    method: str = 'z_score',
    threshold: float = 3.0,
    window_size: int = None
) -> AnomalyResult
```

**å‚æ•°**:
- `data` (pd.Series): è¾“å…¥æ•°æ®
- `method` (str): æ£€æµ‹æ–¹æ³•ï¼Œ'z_score'ã€'iqr'ã€'modified_z_score'
- `threshold` (float): å¼‚å¸¸é˜ˆå€¼
- `window_size` (int): æ»šåŠ¨çª—å£å¤§å°ï¼ˆç”¨äºæ»šåŠ¨æ£€æµ‹ï¼‰

---

## ğŸ¤– æœºå™¨å­¦ä¹ é›†æˆ API

### PredictionEngine ç±»

**åŠŸèƒ½**: å¤šç®—æ³•ä»·æ ¼é¢„æµ‹å¼•æ“

#### åˆå§‹åŒ–
```python
from ml_integration.price_prediction import PredictionEngine

prediction_engine = PredictionEngine(
    random_state=42,          # éšæœºç§å­
    validation_split=0.2,     # éªŒè¯é›†æ¯”ä¾‹
    early_stopping=True       # æ˜¯å¦å¯ç”¨æ—©åœ
)
```

#### æ ¸å¿ƒæ–¹æ³•

##### train_model()
```python
def train_model(
    self,
    features: pd.DataFrame,
    config: ModelConfig,
    save_model: bool = True,
    model_name: str = None
) -> MLModel
```

**å‚æ•°**:
- `features` (pd.DataFrame): ç‰¹å¾æ•°æ®
- `config` (ModelConfig): æ¨¡å‹é…ç½®
- `save_model` (bool): æ˜¯å¦ä¿å­˜æ¨¡å‹
- `model_name` (str): æ¨¡å‹åç§°

**ç¤ºä¾‹**:
```python
from ml_integration import ModelConfig, ModelType, PredictionType

config = ModelConfig(
    model_type=ModelType.RANDOM_FOREST,
    prediction_type=PredictionType.PRICE,
    parameters={
        'n_estimators': 100,
        'max_depth': 10,
        'min_samples_split': 5
    },
    feature_columns=['rsi', 'macd', 'volume_ratio'],
    target_column='future_return_5d'
)

model = prediction_engine.train_model(features, config)
print(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼ŒRÂ²å¾—åˆ†: {model.performance_metrics.r2_score:.3f}")
```

##### predict()
```python
def predict(
    self,
    model: MLModel,
    input_data: pd.DataFrame,
    prediction_horizon: int = 1,
    return_probabilities: bool = False
) -> ModelPrediction
```

##### predict_ensemble()
```python
def predict_ensemble(
    self,
    features: pd.DataFrame,
    models: List[MLModel],
    ensemble_method: str = 'voting',
    weights: List[float] = None
) -> ModelPrediction
```

**å‚æ•°**:
- `features` (pd.DataFrame): è¾“å…¥ç‰¹å¾
- `models` (List[MLModel]): æ¨¡å‹åˆ—è¡¨
- `ensemble_method` (str): é›†æˆæ–¹æ³•ï¼Œ'voting'ã€'averaging'ã€'stacking'
- `weights` (List[float]): æ¨¡å‹æƒé‡

##### backtest_model()
```python
def backtest_model(
    self,
    model: MLModel,
    test_data: pd.DataFrame,
    start_date: str = None,
    end_date: str = None,
    transaction_cost: float = 0.001
) -> BacktestResult
```

### FeatureEngineer ç±»

**åŠŸèƒ½**: ç‰¹å¾å·¥ç¨‹å’Œæ•°æ®é¢„å¤„ç†

#### æ ¸å¿ƒæ–¹æ³•

##### add_technical_features()
```python
def add_technical_features(
    self,
    price_data: pd.DataFrame,
    indicators: List[str] = None,
    periods: Dict[str, List[int]] = None
) -> pd.DataFrame
```

**å‚æ•°**:
- `price_data` (pd.DataFrame): ä»·æ ¼æ•°æ®(OHLCV)
- `indicators` (List[str]): æŠ€æœ¯æŒ‡æ ‡åˆ—è¡¨
- `periods` (Dict): å„æŒ‡æ ‡çš„è®¡ç®—å‘¨æœŸ

**å¯ç”¨æŒ‡æ ‡**:
```python
default_indicators = [
    'rsi', 'macd', 'bollinger_bands', 'stochastic',
    'williams_r', 'cci', 'atr', 'adx', 'obv', 'mfi'
]
```

##### add_market_features()
```python
def add_market_features(
    self,
    features: pd.DataFrame,
    market_data: pd.DataFrame,
    economic_indicators: pd.DataFrame = None
) -> pd.DataFrame
```

##### create_lag_features()
```python
def create_lag_features(
    self,
    data: pd.DataFrame,
    columns: List[str],
    lags: List[int],
    include_rolling_stats: bool = True
) -> pd.DataFrame
```

### TrendAnalysisEngine ç±»

**åŠŸèƒ½**: è¶‹åŠ¿åˆ†æå’Œå˜åŒ–ç‚¹æ£€æµ‹

#### æ ¸å¿ƒæ–¹æ³•

##### analyze_trend_multi_algorithm()
```python
def analyze_trend_multi_algorithm(
    self,
    price_data: pd.Series,
    algorithms: List[str] = None,
    confidence_threshold: float = 0.7
) -> TrendAnalysisResult
```

**å¯ç”¨ç®—æ³•**:
- `'linear_regression'`: çº¿æ€§å›å½’è¶‹åŠ¿
- `'polynomial'`: å¤šé¡¹å¼æ‹Ÿåˆ
- `'moving_average'`: ç§»åŠ¨å¹³å‡è¶‹åŠ¿
- `'exponential_smoothing'`: æŒ‡æ•°å¹³æ»‘
- `'hodrick_prescott'`: HPæ»¤æ³¢

##### detect_trend_changes()
```python
def detect_trend_changes(
    self,
    data: pd.Series,
    method: str = 'pelt',
    sensitivity: float = 0.1,
    min_segment_length: int = 10
) -> ChangePointResult
```

**å˜åŒ–ç‚¹æ£€æµ‹æ–¹æ³•**:
- `'pelt'`: PELTç®—æ³•
- `'binary_segmentation'`: äºŒåˆ†æ³•
- `'window_based'`: æ»‘çª—æ³•
- `'cusum'`: CUSUMæ§åˆ¶å›¾

---

## ğŸ“Š æŠ•èµ„ç»„åˆåˆ†æ API

### PortfolioOptimizer ç±»

**åŠŸèƒ½**: ç°ä»£æŠ•èµ„ç»„åˆç†è®ºä¼˜åŒ–

#### åˆå§‹åŒ–
```python
from portfolio_analytics.portfolio_optimizer import PortfolioOptimizer

optimizer = PortfolioOptimizer(
    risk_free_rate=0.02,      # æ— é£é™©åˆ©ç‡
    max_iterations=1000,      # æœ€å¤§è¿­ä»£æ¬¡æ•°
    tolerance=1e-8,           # æ”¶æ•›å®¹å¿åº¦
    solver='SLSQP'           # ä¼˜åŒ–æ±‚è§£å™¨
)
```

#### æ ¸å¿ƒæ–¹æ³•

##### optimize_portfolio()
```python
def optimize_portfolio(
    self,
    assets: Dict[str, AssetData],
    method: OptimizationMethod,
    constraints: OptimizationConstraints = None,
    objective_params: Dict = None
) -> OptimizationResult
```

**å‚æ•°**:
- `assets` (Dict[str, AssetData]): èµ„äº§æ•°æ®å­—å…¸
- `method` (OptimizationMethod): ä¼˜åŒ–æ–¹æ³•
- `constraints` (OptimizationConstraints): çº¦æŸæ¡ä»¶
- `objective_params` (Dict): ç›®æ ‡å‡½æ•°å‚æ•°

**ä¼˜åŒ–æ–¹æ³•**:
```python
from portfolio_analytics import OptimizationMethod

# å¯ç”¨çš„ä¼˜åŒ–æ–¹æ³•
OptimizationMethod.MINIMUM_VARIANCE      # æœ€å°æ–¹å·®
OptimizationMethod.MAXIMUM_SHARPE        # æœ€å¤§å¤æ™®æ¯”ç‡
OptimizationMethod.MAXIMUM_RETURN        # æœ€å¤§æ”¶ç›Š
OptimizationMethod.RISK_PARITY          # é£é™©å¹³ä»·
OptimizationMethod.MAXIMUM_DIVERSIFICATION  # æœ€å¤§åˆ†æ•£åŒ–
OptimizationMethod.MINIMUM_CVaR          # æœ€å°æ¡ä»¶é£é™©ä»·å€¼
```

**ç¤ºä¾‹**:
```python
from portfolio_analytics import OptimizationConstraints

# è®¾ç½®çº¦æŸæ¡ä»¶
constraints = OptimizationConstraints(
    min_weight=0.05,          # æœ€å°æƒé‡5%
    max_weight=0.40,          # æœ€å¤§æƒé‡40%
    max_assets=10,            # æœ€å¤š10ä¸ªèµ„äº§
    sector_constraints={      # è¡Œä¸šçº¦æŸ
        'Technology': 0.50,   # ç§‘æŠ€è‚¡æœ€å¤š50%
        'Healthcare': 0.30    # åŒ»ç–—è‚¡æœ€å¤š30%
    },
    turnover_constraint=0.20  # æ¢æ‰‹ç‡çº¦æŸ20%
)

# æ‰§è¡Œä¼˜åŒ–
result = optimizer.optimize_portfolio(
    assets=asset_universe,
    method=OptimizationMethod.MAXIMUM_SHARPE,
    constraints=constraints
)

# æŸ¥çœ‹ç»“æœ
if result.optimization_status == "success":
    print(f"æœ€ä¼˜å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.3f}")
    print("æœ€ä¼˜æƒé‡åˆ†é…:")
    for asset, weight in result.optimal_weights.items():
        print(f"  {asset}: {weight:.1%}")
else:
    print(f"ä¼˜åŒ–å¤±è´¥: {result.optimization_status}")
```

##### calculate_efficient_frontier()
```python
def calculate_efficient_frontier(
    self,
    assets: Dict[str, AssetData],
    n_portfolios: int = 100,
    constraints: OptimizationConstraints = None,
    return_range: Tuple[float, float] = None
) -> List[OptimizationResult]
```

**å‚æ•°**:
- `n_portfolios` (int): æœ‰æ•ˆå‰æ²¿ç»„åˆæ•°é‡
- `return_range` (Tuple): æ”¶ç›Šç‡èŒƒå›´(min_return, max_return)

### RiskAnalyzer ç±»

**åŠŸèƒ½**: å…¨é¢çš„é£é™©åˆ†æå’Œç®¡ç†

#### åˆå§‹åŒ–
```python
from portfolio_analytics.risk_analyzer import RiskAnalyzer

risk_analyzer = RiskAnalyzer(
    confidence_levels=[0.95, 0.99],  # VaRç½®ä¿¡æ°´å¹³
    time_horizon=1,                  # é£é™©æ—¶é—´èŒƒå›´(å¤©)
    bootstrap_samples=1000           # Bootstrapæ ·æœ¬æ•°
)
```

#### æ ¸å¿ƒæ–¹æ³•

##### calculate_portfolio_risk_metrics()
```python
def calculate_portfolio_risk_metrics(
    self,
    portfolio: Portfolio,
    benchmark: pd.Series = None
) -> RiskMetrics
```

**è¿”å›çš„é£é™©æŒ‡æ ‡**:
- `portfolio_volatility`: å¹´åŒ–æ³¢åŠ¨ç‡
- `var_95`, `var_99`: é£é™©ä»·å€¼(95%ã€99%ç½®ä¿¡æ°´å¹³)
- `cvar_95`, `cvar_99`: æ¡ä»¶é£é™©ä»·å€¼
- `max_drawdown`: æœ€å¤§å›æ’¤
- `sortino_ratio`: Sortinoæ¯”ç‡
- `calmar_ratio`: Calmaræ¯”ç‡
- `beta`: è´å¡”ç³»æ•°(ç›¸å¯¹åŸºå‡†)
- `tracking_error`: è·Ÿè¸ªè¯¯å·®

**ç¤ºä¾‹**:
```python
risk_metrics = risk_analyzer.calculate_portfolio_risk_metrics(portfolio)

print(f"æŠ•èµ„ç»„åˆé£é™©åˆ†æ:")
print(f"  å¹´åŒ–æ³¢åŠ¨ç‡: {risk_metrics.portfolio_volatility:.2%}")
print(f"  VaR (95%): {risk_metrics.var_95:.2%}")
print(f"  æœ€å¤§å›æ’¤: {risk_metrics.max_drawdown:.2%}")
print(f"  Sortinoæ¯”ç‡: {risk_metrics.sortino_ratio:.3f}")

# é£é™©è¯„ä¼°
if risk_metrics.portfolio_volatility > 0.20:
    print("âš ï¸ è­¦å‘Š: æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡è¾ƒé«˜")
if risk_metrics.max_drawdown < -0.15:
    print("âš ï¸ è­¦å‘Š: æœ€å¤§å›æ’¤è¶…è¿‡15%")
```

##### calculate_var()
```python
def calculate_var(
    self,
    returns: pd.Series,
    confidence_level: float = 0.95,
    method: VaRMethod = VaRMethod.HISTORICAL
) -> float
```

**VaRè®¡ç®—æ–¹æ³•**:
```python
from portfolio_analytics.risk_analyzer import VaRMethod

VaRMethod.HISTORICAL        # å†å²æ¨¡æ‹Ÿæ³•
VaRMethod.PARAMETRIC       # å‚æ•°æ³•(æ­£æ€åˆ†å¸ƒå‡è®¾)
VaRMethod.MONTE_CARLO      # è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ
VaRMethod.CORNISH_FISHER   # Cornish-Fisherå±•å¼€
```

##### calculate_component_var()
```python
def calculate_component_var(
    self,
    portfolio: Portfolio,
    confidence_level: float = 0.95
) -> Dict[str, float]
```

**è¿”å›**: å„èµ„äº§å¯¹æŠ•èµ„ç»„åˆVaRçš„è´¡çŒ®åº¦

##### stress_test()
```python
def stress_test(
    self,
    portfolio: Portfolio,
    stress_type: StressTestType,
    stress_parameters: Dict
) -> Dict[str, float]
```

**å‹åŠ›æµ‹è¯•ç±»å‹**:
```python
from portfolio_analytics.risk_analyzer import StressTestType

StressTestType.FACTOR_SHOCK     # å› å­å†²å‡»
StressTestType.HISTORICAL       # å†å²æƒ…æ™¯
StressTestType.MONTE_CARLO      # è’™ç‰¹å¡æ´›å‹åŠ›æµ‹è¯•
StressTestType.TAIL_RISK        # å°¾éƒ¨é£é™©æƒ…æ™¯
```

**ç¤ºä¾‹**:
```python
# å¸‚åœºä¸‹è·Œå‹åŠ›æµ‹è¯•
stress_params = {
    'market_shock': -0.30,      # å¸‚åœºä¸‹è·Œ30%
    'volatility_shock': 2.0,    # æ³¢åŠ¨ç‡ä¸Šå‡2å€
    'correlation_shock': 0.1    # ç›¸å…³æ€§å¢åŠ 0.1
}

stress_result = risk_analyzer.stress_test(
    portfolio, 
    StressTestType.FACTOR_SHOCK, 
    stress_params
)

print(f"å‹åŠ›æµ‹è¯•ç»“æœ:")
print(f"  æŠ•èµ„ç»„åˆæŸå¤±: {stress_result['portfolio_loss_pct']:.1%}")
print(f"  é£é™©è°ƒæ•´æ”¶ç›Š: {stress_result['risk_adjusted_return']:.3f}")
```

### PerformanceAnalyzer ç±»

**åŠŸèƒ½**: ç»©æ•ˆåˆ†æå’Œå½’å› 

#### æ ¸å¿ƒæ–¹æ³•

##### calculate_performance_metrics()
```python
def calculate_performance_metrics(
    self,
    portfolio: Portfolio,
    benchmark: pd.Series,
    risk_free_rate: float = None
) -> Dict[str, float]
```

**è¿”å›çš„ç»©æ•ˆæŒ‡æ ‡**:
- `total_return`: æ€»æ”¶ç›Šç‡
- `annualized_return`: å¹´åŒ–æ”¶ç›Šç‡
- `volatility`: å¹´åŒ–æ³¢åŠ¨ç‡
- `sharpe_ratio`: å¤æ™®æ¯”ç‡
- `information_ratio`: ä¿¡æ¯æ¯”ç‡
- `alpha`: Alphaç³»æ•°
- `beta`: Betaç³»æ•°
- `max_drawdown`: æœ€å¤§å›æ’¤
- `calmar_ratio`: Calmaræ¯”ç‡

##### brinson_attribution()
```python
def brinson_attribution(
    self,
    portfolio_weights: Dict[str, float],
    benchmark_weights: Dict[str, float],
    portfolio_returns: Dict[str, float],
    benchmark_returns: Dict[str, float],
    sector_mapping: Dict[str, str] = None
) -> BrinsonAttribution
```

**Brinsonå½’å› åˆ†æ**:
- `allocation_effect`: èµ„äº§é…ç½®æ•ˆåº”
- `asset_selection`: è¯åˆ¸é€‰æ‹©æ•ˆåº”  
- `interaction_effect`: äº¤äº’æ•ˆåº”
- `active_return`: ä¸»åŠ¨æ”¶ç›Š
- `sector_attribution`: è¡Œä¸šå½’å› (å¦‚æä¾›sector_mapping)

**ç¤ºä¾‹**:
```python
attribution = performance_analyzer.brinson_attribution(
    portfolio_weights=current_weights,
    benchmark_weights=benchmark_weights,
    portfolio_returns=period_returns,
    benchmark_returns=benchmark_period_returns,
    sector_mapping={'AAPL': 'Technology', 'JPM': 'Financial'}
)

print(f"Brinsonå½’å› åˆ†æ:")
print(f"  èµ„äº§é…ç½®æ•ˆåº”: {attribution.allocation_effect:.4f}")
print(f"  è¯åˆ¸é€‰æ‹©æ•ˆåº”: {attribution.asset_selection:.4f}")
print(f"  äº¤äº’æ•ˆåº”: {attribution.interaction_effect:.4f}")
print(f"  ä¸»åŠ¨æ”¶ç›Š: {attribution.active_return:.4f}")

# è¡Œä¸šçº§å½’å› 
if attribution.sector_attribution:
    print(f"\nè¡Œä¸šå½’å› :")
    for sector, attr in attribution.sector_attribution.items():
        print(f"  {sector}: {attr['total']:.4f}")
```

---

## ğŸ“‹ æ•°æ®ç»“æ„å‚è€ƒ

### AssetData
```python
@dataclass
class AssetData:
    symbol: str                    # è‚¡ç¥¨ä»£ç 
    returns: pd.Series            # æ”¶ç›Šç‡åºåˆ—
    prices: pd.Series             # ä»·æ ¼åºåˆ—
    sector: str = None            # æ‰€å±è¡Œä¸š
    market_cap: float = None      # å¸‚å€¼
    beta: float = None            # è´å¡”ç³»æ•°
    
    def get_statistics(self) -> Dict[str, float]:
        """è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        pass
        
    def calculate_rolling_metrics(self, window: int) -> pd.DataFrame:
        """è®¡ç®—æ»šåŠ¨æŒ‡æ ‡"""
        pass
```

### Portfolio
```python
@dataclass
class Portfolio:
    name: str                           # æŠ•èµ„ç»„åˆåç§°
    weights: Dict[str, float]          # æƒé‡åˆ†é…
    assets: Dict[str, AssetData]       # èµ„äº§æ•°æ®
    inception_date: datetime           # æˆç«‹æ—¥æœŸ
    rebalance_frequency: str = 'monthly'  # å†å¹³è¡¡é¢‘ç‡
    
    def get_portfolio_returns(self) -> pd.Series:
        """è·å–æŠ•èµ„ç»„åˆæ”¶ç›Šç‡"""
        pass
        
    def get_portfolio_statistics(self) -> Dict[str, float]:
        """è·å–æŠ•èµ„ç»„åˆç»Ÿè®¡ä¿¡æ¯"""
        pass
        
    def validate_weights(self) -> bool:
        """éªŒè¯æƒé‡æœ‰æ•ˆæ€§"""
        pass
```

### OptimizationResult
```python
@dataclass
class OptimizationResult:
    optimal_weights: Dict[str, float]    # æœ€ä¼˜æƒé‡
    expected_return: float               # æœŸæœ›æ”¶ç›Š
    expected_risk: float                # æœŸæœ›é£é™©
    sharpe_ratio: float                 # å¤æ™®æ¯”ç‡
    optimization_status: str            # ä¼˜åŒ–çŠ¶æ€
    objective_value: float              # ç›®æ ‡å‡½æ•°å€¼
    optimization_time: float           # ä¼˜åŒ–è€—æ—¶
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        pass
        
    def save_to_file(self, filepath: str):
        """ä¿å­˜åˆ°æ–‡ä»¶"""
        pass
```

### ModelConfig
```python
@dataclass
class ModelConfig:
    model_type: ModelType              # æ¨¡å‹ç±»å‹
    prediction_type: PredictionType    # é¢„æµ‹ç±»å‹
    parameters: Dict                   # æ¨¡å‹å‚æ•°
    feature_columns: List[str]         # ç‰¹å¾åˆ—
    target_column: str                # ç›®æ ‡åˆ—
    validation_method: str = 'time_series'  # éªŒè¯æ–¹æ³•
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        pass
        
    @classmethod
    def from_dict(cls, config_dict: Dict):
        """ä»å­—å…¸åˆ›å»º"""
        pass
```

---

## âš™ï¸ é…ç½®é€‰é¡¹

### å…¨å±€é…ç½®
```python
# config.py
import os

class Config:
    # æ•°æ®é…ç½®
    DATA_CACHE_DIR = os.path.expanduser("~/.quant_cache")
    CACHE_EXPIRY_HOURS = 24
    
    # è®¡ç®—é…ç½®
    PARALLEL_JOBS = -1              # å¹¶è¡Œä»»åŠ¡æ•°(-1ä¸ºæ‰€æœ‰CPU)
    CHUNK_SIZE = 1000              # æ•°æ®å—å¤§å°
    
    # ä¼˜åŒ–é…ç½®
    OPTIMIZATION_TIMEOUT = 300      # ä¼˜åŒ–è¶…æ—¶(ç§’)
    MAX_ITERATIONS = 1000          # æœ€å¤§è¿­ä»£æ¬¡æ•°
    TOLERANCE = 1e-8               # æ”¶æ•›å®¹å¿åº¦
    
    # é£é™©é…ç½®
    DEFAULT_CONFIDENCE_LEVELS = [0.95, 0.99]
    VAR_BOOTSTRAP_SAMPLES = 1000
    STRESS_TEST_SCENARIOS = 1000
    
    # MLé…ç½®
    VALIDATION_SPLIT = 0.2
    EARLY_STOPPING_PATIENCE = 10
    CROSS_VALIDATION_FOLDS = 5
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL = "INFO"
    LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
```

### ç¯å¢ƒå˜é‡
```bash
# .env æ–‡ä»¶
QUANT_DATA_SOURCE=yahoo           # æ•°æ®æº
QUANT_CACHE_DIR=/path/to/cache   # ç¼“å­˜ç›®å½•
QUANT_LOG_LEVEL=INFO             # æ—¥å¿—çº§åˆ«
QUANT_PARALLEL_JOBS=4            # å¹¶è¡Œä»»åŠ¡æ•°
QUANT_RISK_FREE_RATE=0.02        # æ— é£é™©åˆ©ç‡
```

### ä½¿ç”¨é…ç½®
```python
from config import Config
import os

# æ›´æ–°é…ç½®
Config.PARALLEL_JOBS = int(os.getenv('QUANT_PARALLEL_JOBS', -1))
Config.DATA_CACHE_DIR = os.getenv('QUANT_CACHE_DIR', Config.DATA_CACHE_DIR)

# åœ¨ç»„ä»¶ä¸­ä½¿ç”¨
optimizer = PortfolioOptimizer(
    max_iterations=Config.MAX_ITERATIONS,
    tolerance=Config.TOLERANCE
)
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### é”™è¯¯å¤„ç†ç¤ºä¾‹
```python
try:
    result = optimizer.optimize_portfolio(assets, method, constraints)
    if result.optimization_status != "success":
        logger.warning(f"ä¼˜åŒ–è­¦å‘Š: {result.optimization_status}")
        # å®æ–½å›é€€ç­–ç•¥
        
except OptimizationError as e:
    logger.error(f"ä¼˜åŒ–å¤±è´¥: {e}")
    # é”™è¯¯å¤„ç†é€»è¾‘
    
except InsufficientDataError as e:
    logger.error(f"æ•°æ®ä¸è¶³: {e}")
    # æ•°æ®å¤„ç†é€»è¾‘
```

### æ€§èƒ½ç›‘æ§
```python
import time
from functools import wraps

def monitor_performance(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        execution_time = time.time() - start_time
        
        if execution_time > 60:  # è¶…è¿‡1åˆ†é’Ÿ
            logger.warning(f"{func.__name__} æ‰§è¡Œæ—¶é—´è¾ƒé•¿: {execution_time:.2f}ç§’")
            
        return result
    return wrapper

# ä½¿ç”¨è£…é¥°å™¨
@monitor_performance
def expensive_calculation():
    pass
```

---

*APIæ–‡æ¡£ç‰ˆæœ¬: v1.0 | æœ€åæ›´æ–°: 2025å¹´10æœˆ1æ—¥*