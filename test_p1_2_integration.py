"""
P1-2é«˜çº§ç»„ä»¶é›†æˆæµ‹è¯•

æµ‹è¯•ä»¥ä¸‹æ¨¡å—çš„é›†æˆï¼š
1. é«˜çº§åˆ†æç»„ä»¶
2. æœºå™¨å­¦ä¹ é›†æˆ
3. æŠ•èµ„ç»„åˆåˆ†æå·¥å…·
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(project_root, 'src')
sys.path.insert(0, src_path)

def test_advanced_analytics():
    """æµ‹è¯•é«˜çº§åˆ†æç»„ä»¶"""
    print("=== æµ‹è¯•é«˜çº§åˆ†æç»„ä»¶ ===")
    
    try:
        # 1. æŠ€æœ¯æŒ‡æ ‡æµ‹è¯•
        from advanced_analytics.technical_indicators import AdvancedIndicators, IndicatorEngine
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')
        np.random.seed(42)
        
        # ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ä»·æ•°æ®
        returns = np.random.normal(0.001, 0.02, len(dates))
        prices = 100 * np.exp(np.cumsum(returns))
        
        test_data = pd.DataFrame({
            'close': prices,
            'high': prices * (1 + np.abs(np.random.normal(0, 0.01, len(dates)))),
            'low': prices * (1 - np.abs(np.random.normal(0, 0.01, len(dates)))),
            'volume': np.random.randint(1000000, 10000000, len(dates))
        }, index=dates)
        
        test_data['open'] = test_data['close'].shift(1).fillna(test_data['close'].iloc[0])
        
        # æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡
        indicators = AdvancedIndicators()
        
        # è‡ªé€‚åº”ç§»åŠ¨å¹³å‡
        adaptive_ma = indicators.adaptive_moving_average(test_data['close'])
        print(f"âœ“ è‡ªé€‚åº”ç§»åŠ¨å¹³å‡è®¡ç®—æˆåŠŸ: {len(adaptive_ma)} ä¸ªæ•°æ®ç‚¹")
        
        # VWAPå¸¦
        vwap_bands = indicators.vwap_bands(test_data)
        print(f"âœ“ VWAPå¸¦è®¡ç®—æˆåŠŸ: {len(vwap_bands)} ä¸ªæ•°æ®ç‚¹")
        
        # ä¸€ç›®å‡è¡¡è¡¨
        ichimoku = indicators.ichimoku_cloud(test_data)
        print(f"âœ“ ä¸€ç›®å‡è¡¡è¡¨è®¡ç®—æˆåŠŸ: {len(ichimoku)} ä¸ªæ•°æ®ç‚¹")
        
        # 2. ç»Ÿè®¡åˆ†ææµ‹è¯•
        from advanced_analytics.statistical_analysis import StatisticalAnalyzer
        
        analyzer = StatisticalAnalyzer()
        
        # ç›¸å…³æ€§åˆ†æ
        returns_data = test_data[['close', 'volume']].pct_change().dropna()
        correlation_result = analyzer.correlation_analysis(returns_data)
        print(f"âœ“ ç›¸å…³æ€§åˆ†æå®Œæˆ: æ–¹æ³•æ•°é‡ {len(correlation_result.methods)}")
        
        # åˆ†å¸ƒåˆ†æ
        distribution_result = analyzer.distribution_analysis(returns_data['close'])
        print(f"âœ“ åˆ†å¸ƒåˆ†æå®Œæˆ: åˆ†å¸ƒç±»å‹ {distribution_result.best_fit_distribution}")
        
        # 3. å¼‚å¸¸æ£€æµ‹æµ‹è¯•
        from advanced_analytics.anomaly_detection import AnomalyDetectionEngine
        
        anomaly_engine = AnomalyDetectionEngine()
        anomaly_report = anomaly_engine.comprehensive_anomaly_detection(
            test_data['close'], 
            'TEST_SYMBOL',
            methods=['zscore', 'iqr', 'sudden_change']
        )
        print(f"âœ“ å¼‚å¸¸æ£€æµ‹å®Œæˆ: å‘ç° {len(anomaly_report.anomalies)} ä¸ªå¼‚å¸¸ç‚¹")
        
        # 4. å¯è§†åŒ–æµ‹è¯•
        from advanced_analytics.visualization import VisualizationEngine, ChartConfig
        
        viz_engine = VisualizationEngine()
        
        # åˆ›å»ºæŠ€æœ¯åˆ†æå›¾è¡¨
        indicators_dict = {
            'Adaptive_MA': adaptive_ma,
            'VWAP': vwap_bands['vwap'] if 'vwap' in vwap_bands.columns else pd.Series()
        }
        
        try:
            chart = viz_engine.create_comprehensive_chart(
                test_data, 
                indicators=indicators_dict,
                anomalies=anomaly_report.anomalies[:5]  # åªæ˜¾ç¤ºå‰5ä¸ªå¼‚å¸¸ç‚¹
            )
            print("âœ“ ç»¼åˆå›¾è¡¨åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"â—‹ å›¾è¡¨åˆ›å»ºè·³è¿‡ï¼ˆä¾èµ–é¡¹ç¼ºå¤±ï¼‰: {str(e)}")
        
        print("âœ… é«˜çº§åˆ†æç»„ä»¶æµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"âŒ é«˜çº§åˆ†æç»„ä»¶æµ‹è¯•å¤±è´¥: {str(e)}\n")
        return False


def test_ml_integration():
    """æµ‹è¯•æœºå™¨å­¦ä¹ é›†æˆ"""
    print("=== æµ‹è¯•æœºå™¨å­¦ä¹ é›†æˆ ===")
    
    try:
        # 1. ä»·æ ¼é¢„æµ‹æµ‹è¯•
        from ml_integration.price_prediction import FeatureEngineer, PredictionEngine, LinearRegressionModel
        from ml_integration import ModelConfig, PredictionType, ModelType
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')
        np.random.seed(42)
        
        returns = np.random.normal(0.001, 0.02, len(dates))
        prices = 100 * np.exp(np.cumsum(returns))
        
        test_data = pd.DataFrame({
            'close': prices,
            'high': prices * 1.02,
            'low': prices * 0.98,
            'volume': np.random.randint(1000000, 10000000, len(dates)),
            'open': np.concatenate([[prices[0]], prices[:-1]])
        }, index=dates)
        
        # ç‰¹å¾å·¥ç¨‹
        feature_engineer = FeatureEngineer()
        features = feature_engineer.create_technical_features(test_data)
        print(f"âœ“ æŠ€æœ¯ç‰¹å¾åˆ›å»ºæˆåŠŸ: {len(features.columns)} ä¸ªç‰¹å¾")
        
        # åˆ›å»ºç›®æ ‡å˜é‡
        targets = feature_engineer.create_target_variables(test_data)
        print(f"âœ“ ç›®æ ‡å˜é‡åˆ›å»ºæˆåŠŸ: {len(targets.columns)} ä¸ªç›®æ ‡")
        
        # é¢„æµ‹å¼•æ“æµ‹è¯•
        prediction_engine = PredictionEngine()
        
        # åˆ›å»ºçº¿æ€§å›å½’æ¨¡å‹
        config = ModelConfig(
            model_type=ModelType.REGRESSION,
            prediction_type=PredictionType.PRICE,
            parameters={},
            feature_columns=['returns', 'ma_5', 'ma_10', 'rsi'],
            target_column='future_return'
        )
        
        try:
            model = LinearRegressionModel('test_linear', config)
            prediction_engine.add_model(model)
            print("âœ“ çº¿æ€§å›å½’æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        except ImportError:
            print("â—‹ çº¿æ€§å›å½’æ¨¡å‹è·³è¿‡ï¼ˆsklearnä¸å¯ç”¨ï¼‰")
        
        # 2. è¶‹åŠ¿åˆ†ææµ‹è¯•
        from ml_integration.trend_analysis import TrendAnalysisEngine, TrendDetector
        
        trend_engine = TrendAnalysisEngine()
        trend_results = trend_engine.comprehensive_trend_analysis(test_data['close'], 'TEST')
        
        print(f"âœ“ è¶‹åŠ¿åˆ†æå®Œæˆ: {len(trend_results)} ç§æ–¹æ³•")
        for method, result in trend_results.items():
            print(f"  - {method}: {result.direction.value}, å¼ºåº¦: {result.strength.value}")
        
        # 3. æƒ…æ„Ÿåˆ†ææµ‹è¯•
        from ml_integration.sentiment_analysis import SentimentAnalysisEngine, TextSentimentAnalyzer
        
        sentiment_engine = SentimentAnalysisEngine()
        
        # æµ‹è¯•æ–‡æœ¬æƒ…æ„Ÿåˆ†æ
        text_analyzer = TextSentimentAnalyzer()
        test_news = [
            "Company reports strong earnings growth with bullish outlook",
            "Market concerns over bearish economic indicators",
            "Positive momentum in technology sector drives gains"
        ]
        
        for text in test_news:
            sentiment = text_analyzer.analyze_text(text)
            print(f"âœ“ æ–‡æœ¬æƒ…æ„Ÿåˆ†æ: '{text[:30]}...' -> {sentiment.get_sentiment_label().value}")
        
        # ç»¼åˆæƒ…æ„Ÿåˆ†æ
        market_sentiment = sentiment_engine.comprehensive_sentiment_analysis(
            'TEST',
            test_data,
            news_texts=test_news
        )
        print(f"âœ“ ç»¼åˆæƒ…æ„Ÿåˆ†æå®Œæˆ: {market_sentiment.sentiment_label.value}")
        
        print("âœ… æœºå™¨å­¦ä¹ é›†æˆæµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"âŒ æœºå™¨å­¦ä¹ é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}\n")
        return False


def test_portfolio_analytics():
    """æµ‹è¯•æŠ•èµ„ç»„åˆåˆ†æå·¥å…·"""
    print("=== æµ‹è¯•æŠ•èµ„ç»„åˆåˆ†æå·¥å…· ===")
    
    try:
        from portfolio_analytics import AssetData, Portfolio, OptimizationConstraints
        from portfolio_analytics.portfolio_optimizer import PortfolioOptimizer
        from portfolio_analytics.risk_analyzer import RiskAnalyzer
        from portfolio_analytics.performance_attribution import PerformanceAnalyzer
        
        # 1. åˆ›å»ºæµ‹è¯•èµ„äº§æ•°æ®
        np.random.seed(42)
        dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')
        
        assets = {}
        symbols = ['AAPL', 'GOOGL', 'MSFT', 'TSLA']
        
        for symbol in symbols:
            returns = pd.Series(
                np.random.normal(0.001, 0.02, len(dates)),
                index=dates,
                name=symbol
            )
            prices = pd.Series(
                100 * np.exp(np.cumsum(returns)),
                index=dates,
                name=symbol
            )
            
            assets[symbol] = AssetData(
                symbol=symbol,
                returns=returns,
                prices=prices,
                sector='Technology',
                market_cap=1e12,
                beta=1.2
            )
        
        print(f"âœ“ åˆ›å»º {len(assets)} ä¸ªæµ‹è¯•èµ„äº§")
        
        # 2. åˆ›å»ºæŠ•èµ„ç»„åˆ
        weights = {'AAPL': 0.3, 'GOOGL': 0.25, 'MSFT': 0.25, 'TSLA': 0.2}
        portfolio = Portfolio(
            name='Test Portfolio',
            weights=weights,
            assets=assets,
            inception_date=dates[0]
        )
        
        portfolio_returns = portfolio.get_portfolio_returns()
        print(f"âœ“ æŠ•èµ„ç»„åˆåˆ›å»ºæˆåŠŸ: {len(portfolio_returns)} ä¸ªæ”¶ç›Šç‡æ•°æ®ç‚¹")
        
        # éªŒè¯æƒé‡
        assert portfolio.validate_weights(), "æƒé‡éªŒè¯å¤±è´¥"
        print("âœ“ æŠ•èµ„ç»„åˆæƒé‡éªŒè¯é€šè¿‡")
        
        # 3. æŠ•èµ„ç»„åˆä¼˜åŒ–æµ‹è¯•
        optimizer = PortfolioOptimizer()
        constraints = OptimizationConstraints(min_weight=0.1, max_weight=0.4)
        
        try:
            from portfolio_analytics import OptimizationMethod
            result = optimizer.optimize_portfolio(
                assets,
                OptimizationMethod.MINIMUM_VARIANCE,
                constraints
            )
            print(f"âœ“ æŠ•èµ„ç»„åˆä¼˜åŒ–å®Œæˆ: {result.optimization_status}")
            if result.optimization_status == "success":
                print(f"  - æœŸæœ›æ”¶ç›Š: {result.expected_return:.4f}")
                print(f"  - æœŸæœ›é£é™©: {result.expected_risk:.4f}")
                print(f"  - å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.4f}")
        except ImportError:
            print("â—‹ æŠ•èµ„ç»„åˆä¼˜åŒ–è·³è¿‡ï¼ˆscipyä¸å¯ç”¨ï¼‰")
        
        # 4. é£é™©åˆ†ææµ‹è¯•
        risk_analyzer = RiskAnalyzer()
        risk_metrics = risk_analyzer.calculate_portfolio_risk_metrics(portfolio)
        
        print(f"âœ“ é£é™©åˆ†æå®Œæˆ:")
        print(f"  - æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡: {risk_metrics.portfolio_volatility:.4f}")
        print(f"  - VaR (95%): {risk_metrics.var_95:.4f}")
        print(f"  - CVaR (95%): {risk_metrics.cvar_95:.4f}")
        print(f"  - æœ€å¤§å›æ’¤: {risk_metrics.max_drawdown:.4f}")
        
        # æˆåˆ†VaRåˆ†æ
        try:
            component_var = risk_analyzer.calculate_component_var(portfolio)
            print(f"âœ“ æˆåˆ†VaRè®¡ç®—å®Œæˆ: {len(component_var)} ä¸ªç»„ä»¶")
        except Exception as e:
            print(f"â—‹ æˆåˆ†VaRè®¡ç®—è·³è¿‡: {str(e)}")
        
        # 5. ç»©æ•ˆå½’å› æµ‹è¯•
        performance_analyzer = PerformanceAnalyzer()
        
        # åˆ›å»ºåŸºå‡†æ”¶ç›Šç‡
        benchmark_returns = pd.Series(
            np.random.normal(0.0008, 0.015, len(dates)),
            index=dates
        )
        
        performance_metrics = performance_analyzer.calculate_performance_metrics(
            portfolio, 
            benchmark_returns
        )
        
        print(f"âœ“ ç»©æ•ˆåˆ†æå®Œæˆ:")
        print(f"  - æ€»æ”¶ç›Š: {performance_metrics.get('total_return', 0):.4f}")
        print(f"  - å¤æ™®æ¯”ç‡: {performance_metrics.get('sharpe_ratio', 0):.4f}")
        print(f"  - ä¿¡æ¯æ¯”ç‡: {performance_metrics.get('information_ratio', 0):.4f}")
        print(f"  - è·Ÿè¸ªè¯¯å·®: {performance_metrics.get('tracking_error', 0):.4f}")
        
        # Brinsonå½’å› åˆ†æ
        try:
            benchmark_weights = {'AAPL': 0.25, 'GOOGL': 0.25, 'MSFT': 0.25, 'TSLA': 0.25}
            portfolio_period_returns = {symbol: assets[symbol].returns.mean() for symbol in symbols}
            benchmark_period_returns = {symbol: assets[symbol].returns.mean() * 0.9 for symbol in symbols}
            
            attribution = performance_analyzer.brinson_attribution(
                weights,
                benchmark_weights,
                portfolio_period_returns,
                benchmark_period_returns
            )
            
            print(f"âœ“ Brinsonå½’å› åˆ†æå®Œæˆ:")
            print(f"  - é…ç½®æ•ˆåº”: {attribution.allocation_effect:.4f}")
            print(f"  - é€‰æ‹©æ•ˆåº”: {attribution.asset_selection:.4f}")
            print(f"  - äº¤äº’æ•ˆåº”: {attribution.interaction_effect:.4f}")
            
        except Exception as e:
            print(f"â—‹ Brinsonå½’å› åˆ†æè­¦å‘Š: {str(e)}")
        
        print("âœ… æŠ•èµ„ç»„åˆåˆ†æå·¥å…·æµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"âŒ æŠ•èµ„ç»„åˆåˆ†æå·¥å…·æµ‹è¯•å¤±è´¥: {str(e)}\n")
        return False


def test_integration():
    """æµ‹è¯•æ¨¡å—é—´é›†æˆ"""
    print("=== æµ‹è¯•æ¨¡å—é—´é›†æˆ ===")
    
    try:
        # åˆ›å»ºç»¼åˆåˆ†ææµç¨‹
        # 1. æ•°æ®å‡†å¤‡
        dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')
        np.random.seed(42)
        
        # 2. é«˜çº§åˆ†æ -> æœºå™¨å­¦ä¹  -> æŠ•èµ„ç»„åˆä¼˜åŒ–æµç¨‹
        from advanced_analytics.technical_indicators import AdvancedIndicators
        from ml_integration.trend_analysis import TrendAnalysisEngine
        from portfolio_analytics import AssetData, Portfolio
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        returns = np.random.normal(0.001, 0.02, len(dates))
        prices = 100 * np.exp(np.cumsum(returns))
        
        test_data = pd.DataFrame({
            'close': prices,
            'high': prices * 1.02,
            'low': prices * 0.98,
            'volume': np.random.randint(1000000, 10000000, len(dates))
        }, index=dates)
        
        # é«˜çº§æŠ€æœ¯åˆ†æ
        indicators = AdvancedIndicators()
        rsi = indicators.rsi(test_data['close'])
        
        # è¶‹åŠ¿åˆ†æ
        trend_engine = TrendAnalysisEngine()
        trend_analysis = trend_engine.comprehensive_trend_analysis(test_data['close'])
        
        # ç»“åˆæŠ€æœ¯æŒ‡æ ‡å’Œè¶‹åŠ¿åˆ†æåˆ›å»ºæŠ•èµ„ä¿¡å·
        signals = []
        if trend_analysis['linear'].direction.value == 'uptrend':
            signals.append('BUY_SIGNAL')
        
        current_rsi = rsi.dropna().iloc[-1] if len(rsi.dropna()) > 0 else 50
        if current_rsi < 30:
            signals.append('OVERSOLD')
        elif current_rsi > 70:
            signals.append('OVERBOUGHT')
        
        print(f"âœ“ ç»¼åˆä¿¡å·ç”Ÿæˆ: {signals}")
        
        # åˆ›å»ºèµ„äº§å¹¶æ„å»ºæŠ•èµ„ç»„åˆ
        asset = AssetData(
            symbol='TEST',
            returns=test_data['close'].pct_change().dropna(),
            prices=test_data['close'],
            sector='Technology'
        )
        
        portfolio = Portfolio(
            name='Integrated Test Portfolio',
            weights={'TEST': 1.0},
            assets={'TEST': asset}
        )
        
        portfolio_stats = portfolio.get_portfolio_statistics()
        print(f"âœ“ é›†æˆæŠ•èµ„ç»„åˆç»Ÿè®¡: å¤æ™®æ¯”ç‡ {portfolio_stats.get('sharpe_ratio', 0):.4f}")
        
        print("âœ… æ¨¡å—é—´é›†æˆæµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å—é—´é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}\n")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹P1-2é«˜çº§ç»„ä»¶é›†æˆæµ‹è¯•")
    print("=" * 50)
    
    test_results = []
    
    # è¿è¡Œå„æ¨¡å—æµ‹è¯•
    test_results.append(test_advanced_analytics())
    test_results.append(test_ml_integration())
    test_results.append(test_portfolio_analytics())
    test_results.append(test_integration())
    
    # æ±‡æ€»ç»“æœ
    print("=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    test_names = [
        "é«˜çº§åˆ†æç»„ä»¶",
        "æœºå™¨å­¦ä¹ é›†æˆ", 
        "æŠ•èµ„ç»„åˆåˆ†æå·¥å…·",
        "æ¨¡å—é—´é›†æˆ"
    ]
    
    passed_tests = 0
    for i, (name, result) in enumerate(zip(test_names, test_results)):
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{i+1}. {name}: {status}")
        if result:
            passed_tests += 1
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed_tests}/{len(test_results)} æµ‹è¯•é€šè¿‡")
    
    if passed_tests == len(test_results):
        print("ğŸ‰ æ‰€æœ‰P1-2é«˜çº§ç»„ä»¶æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ P1-2ç»„ä»¶åŠŸèƒ½æ€»ç»“:")
        print("âœ“ é«˜çº§æŠ€æœ¯æŒ‡æ ‡åˆ†æ")
        print("âœ“ ç»Ÿè®¡åˆ†æå’Œå¼‚å¸¸æ£€æµ‹")
        print("âœ“ ä¸“ä¸šé‡‘èå¯è§†åŒ–")
        print("âœ“ æœºå™¨å­¦ä¹ ä»·æ ¼é¢„æµ‹")
        print("âœ“ æ™ºèƒ½è¶‹åŠ¿åˆ†æ")
        print("âœ“ å¤šæºæƒ…æ„Ÿåˆ†æ")
        print("âœ“ ç°ä»£æŠ•èµ„ç»„åˆç†è®º")
        print("âœ“ å…¨é¢é£é™©ç®¡ç†")
        print("âœ“ ä¸“ä¸šç»©æ•ˆå½’å› ")
        
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œä½†æ ¸å¿ƒåŠŸèƒ½å¯ç”¨")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)